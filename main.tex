\documentclass{sig-alternate-05-2015}
\usepackage{amsmath}
\usepackage{amssymb}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\usepackage{mathrsfs}

\begin{document}

\setcopyright{acmcopyright}

\title{Improving Collaborative Filtering with\\
Long-Short Interest Model}

\numberofauthors{1}
\author{
\alignauthor
Chao Lv \quad
Lili Yao \quad
Yansong Feng \quad
Dongyan Zhao\titlenote{Corresponding author.}\\
\affaddr{Institute of Computer Science and Technology}\\
\affaddr{Peking University, Beijing 100871, China}\\
\email{\{lvchao, yaolili, fengyansong, zhaodongyan\}@pku.edu.cn}
}

\maketitle

\begin{abstract}
Collaborative filtering (CF) has been widely employed within
recommender systems in many real-world situations.
The basic assumption of CF is that items liked by the same user would be similar and
users like same items would share similar interest.
But it is not always true since the user's interest changes over time.
It should be more reasonable to assume that
if these items are liked by the same user in the same time period,
there is a strong possibility that they are similar,
but the possibility will shrink if the user likes they in different time period.
In this paper, we propose a long-short interest model (LSIM) based on
the new assumption to improve collaborative filtering.
In special, we introduce a neural network based language model
to extract the sequential features on user's preference over time.
Then, we integrate the sequential features to solve the rating prediction task
in a feature based collaborative filtering framework.
Experimental results on three MovieLens datasets demonstrate that
our approach can achieve the state-of-the-art performance.
\end{abstract}

\category{H.3.3}{Information Search and Retrieval}{Information Filtering}
\category{H.2.8}{Database Management}{Data Mining}
\keywords{Recommender System; Collaborative Filtering; Long-Short Interest Model;}

\section{Introduction}
In the modern era of information overload,
recommender system (RS) has become more and more popular in many real-world situations.
Recommender system aims to help users find the items,
they are more likely to be interested in,
from huge amounts of candidates.
Lots of websites (e.g. Amazon, Netflix, Alibaba and Hulu) use recommender system to
target customers and provide them with useful information.
An excellent recommendation system can effectively increase the amount of sales.
For instance, 80\% of movies watched on Netflix
come from their recommender system \cite{gomez2015netflix}.

A widely used setting of recommender system \cite{ricci2011introduction} is to
predict the rating a user will evaluate on a new item (such as a movie)
given the past rating history of the users.
Lots of classical recommendation methods have been proposed
during the last decade, and they can be categorized into two classes:
content based methods and collaborative filtering based methods.
Content based methods \cite{pazzani2007content} take advantage of
user profiles and item properties for recommendation.
While collaborative filtering based approaches \cite{su2009survey} utilize
the past interactions or preferences, such as users' ratings on items,
without using user or product content information for recommendation.
Collaborative filtering based approaches have attracted more attention
due to their impressive performance, and developed for many years and
keep to be a hot area in both academia and industry.

\begin{figure}[htbp]
    \centering
    \includegraphics[scale=0.7]{images/example.pdf}
    \caption{The preference records of user whose id is $5988$ in MovieLens-1M dataset,
    which are sorted by their rated time.}
    \label{fig:example}
\end{figure}

Collaborative filtering assumes that items liked by the same user would be similar and
users like same items would share similar interest.
However, it is not always true because the user's interest changes over time.
For example, given a user in MovieLens-1M dataset whose id is $5988$,
Figure \label{fig:example} shows the movies he watched sorted by the rating time.
We can find that this user liked watching comedy movies in April 2004 and
changed to love watching drama movies in June 2004.
Thses movies are going to be treated similar in conventional collaborative filtering,
but they are not in actual.
A more reasonable assumption, aka long-short interest assumption, should be that
items liked by the same user in the same time period have a higher possibility
to be similar than items liked by the same user in different time period.

\begin{figure*}[htbp]
    \centering
    \includegraphics[scale=0.38]{images/example2.pdf}
    \caption{Paragraph2vec learns vector representations of sentences and words
    based on the word order
    while LSIM extracts sequential features of users and items
    based on the rating order.
    }
    \label{fig:example2}
\end{figure*}

Inspired by paragraph2vec algorithm \cite{le2014distributed} for
learning vector representations of words which take advantage of
a word order observed in a sentence,
we introduce a long-short interest model (LSIM) to extract sequential features
of users and items based on the new assumption.
As illustrated in Figure \ref{fig:example2}, user is simliar with the sentence,
both of them contains a sequence follow some order,
and items are similar with words because both of them follow the law
that the more close they are, the more similar they are.
To verify the effectiveness of the learned sequential features of users
and items, we integrate them as side information to solve the rating prediction task
in a feature based collaborative filtering framework.

The main contributions of this paper include:
(1) We introduce a long-short interest model (LSIM) to extract sequential features
of users and items based on the long-short interest assumption.
(2) We demonstrate the effectiveness of the sequential features
via integrating them as side information to solve the rating prediction task.
(3) Experiments on three public MovieLens shows LSIM can achieve the state-of-the-art performance.

The rest of the paper is organized as follows. Section 2 gives an overview of the related work.
Then, we describe our long-short interest model and the feature based collaborative filtering
framework in Section 3. The experimental results as well as the comparisons with
baseline system are shown in Section 4.
Finally, we conclude the paper and outline our future work in Section 5.

\section{Related Work}
Our work is closely related to collaborative filtering and
neural network language model.
We will discuss them in the following subsections.

\subsection{Collaborative Filtering}
Collaborative filtering based methods can mainly divided into three categories:
user-based collaborative filtering, item-based collaborative filtering and
model-based collaborative filtering.
User-based collaborative filtering \cite{resnick1994grouplens} recommends
items liked by users who are simliar with you
while item-based collaborative filtering \cite{sarwar2001item} aims to
recommend items similar with ones you liked in the past.
Matrix factorization (MF) is the most popular model-based collaborative filtering methods,
their success at the Netflix competition \cite{koren2009matrix, bennett2007netflix}
have demonstrated their amazing strength,
and lots of variants of it have been proposed in the following works.

Basically, the given ratings matrix $\mathbf{R} \in \mathbb{R}^{N*M}$
consisting of the item preferences of the users can be decomposed as
a product of two low dimensional matrices $\mathbf{U} \in \mathbb{R}^{N*K}$
and $\mathbf{V} \in \mathbb{R}^{K*M}$.
$\mathbf{U}$ could be treated as a user-interest matrix while
$\mathbf{U}$ could be treated as a item-interest matrix.
$K$ is the amount of interest.
The decomposition can be carried out by a variety of methods
such as singular value decomposition (SVD) based approaches \cite{mazumder2010spectral},
non-negative matrix factorization approach \cite{lee2001algorithms}
and regularized alternative least square (ALS) algorithm \cite{zhou2008large}.
Meanwhile, non-linear algorithms are proposed to catch subtle factors,
such as Non Linear Probabilistic Matrix Factorization \cite{lawrence2009non},
Factorization Machines \cite{rendle2010factorization} and
Local Low Rank Matrix Approximation \cite{lee2013local}.
However, these mothodes group users and treat items they rated equally,
which will lose the sequential features to describe the long-short interest.

Matrix factorization methods suffer from the cold start problem,
i.e. what recommendations to make when a new user/item arrives in the system.
Another problem often presented in many real world applications is data sparsity.
Incorporating side information has shown promising performance
in collaborative filtering in such scenarios.
In recent years, deep learning \cite{hinton2006reducing, hinton2006fast}
has attracted a lot of attention due to its amazing performance
to learn representations on various tasks,
especially in computer vision and natural language processing.
Hence, some works make use of deep learning to learn effective
features from side information to improve the performance of recommender system,
such as \cite{salakhutdinov2007restricted, van2013deep, wang2015collaborative, li2015deep}.

Neural Networks have attracted little attention in the collaborative filtering community.
Salakhutdinov \textit{et al.} \cite{salakhutdinov2007restricted} were the first
work to tackle the Netflix challenge using Restricted Boltzmann Machines (RBM).
They modified the RBM as a two-layer undirected graphical model
consisting of binary hidden units and softmax visible units,
and tested their model on the Netflix dataset and
showed a comparable result with the start-of-the-art.
On music recommendation, Van \textit{et al.} \cite{van2013deep}
directly use Convolutional Neural Network (CNN) to learn effective representations
of songs and use them in content-based collaborative filtering framework.
Wang \textit{et al.} \cite{wang2015collaborative} 
directly coupled matrix factorization with deep learning models,
and proposed a hierarchical Bayesian model called Collaborative Deep Learning (CDL)
which tightly couples Stacked Denoising AutoEncoders (SDA) \cite{vincent2008extracting} and
Collaborative Topic Regression (CTR) \cite{wang2011collaborative} to solve the cold start problem.
Li \textit{et al.} \cite{li2015deep} proposed a generate learning framework
to combine rating matrix and side information, they used 
Probabilistic matrix factorization (PMF) \cite{salakhutdinov2011probabilistic} and
marginalized Stacked Denoising AutoEncoders (mSDA) \cite{chen2012marginalized}
in their approach, which is close to CDL but more efficient and scalable.
Meanwhile, their model can learn deep features for both items and users
while CDL only extracts deep features for items.
In our work, although sequential features learned by LSIM are used as side information
in the feature based collaborative framework, but actually they aims to describe
the long-short interest, and cann't be utilized to solve the cold start problem.

\subsection{Nerual Network Language Model}
Traditional language model uses a one-hot representation to represent each word
as a feature vector, where these feature vectors have the same length as the size
of vocabulary, and the position that corresponds to the observed word is equal to 1,
and 0 otherwise. However, this approach often exhibits significant limitations
in practical tasks, suffering from high dimensionality and severe data sparsity.

Mikolov \textit{et al.} \cite{mikolov2013efficient, mikolov2013distributed} proposed
the word2vec algorithm to address these issues. They take advantage of the word order
in text documents, explicitly modeling the assumption that closer words in the word
sequence are statistically more dependent, and have generalized the classic n-gram
language models by using continuous variables to represent words in a vector space.
The continuous bag-of-words (CBOW) and skip-gram (SG) language models are highly
scalable for learning word representations from large-scale corpora.
The word2vec algorithm breaks the semantic gap between words.
For example, ``trade'' and ``deal'' are totally different words in the one-hot representation,
but they are similar in word2vec distribution representation.
Le \textit{et al.} \cite{le2014distributed} followed the above work and proposed
the paragraph2vec algorithm to simultaneously learn vector representations of sentence
and words by considering the sentence as a ``global context".
Our long-short interest model shares similar idea with paragraph2vec algorithm,
but we aim to simultaneously learn vector representations of user and items
correspondingly by considering the user as a ``global context".

\section{Our Approach}
In this section,
we first describe the definition of the rating prediction task and
the notation we are going to use in this paper.
Then we introduce our long-short interest model to extract the sequential features
of users and items based on the long-short interest assumption.
In the last, we utilize the sequential features as side information
in the feature based collaborative filtering framework to make the final prediction.

\subsection{Problem Definition}
Given $N$ users and $M$ items, the rating $r_{ij}$ is the rating given by
the $i^{th}$ user for the $j^{th}$ item.
In the common real-world situations,
users usually rate on a fraction of items, not on the whole items.
Therefore,
those ratings entail a big and sparse matrix $\mathbf{R} \in \mathbb{R}^{N \times M}$.
The goal of recommender system is to make a prediction on the missing ratings.
Based on that, we will know the preference of a user on the items he never rates,
and recommend high score items to him.

Matrix Factorization is a classic method to solve this problem.
It aims to find a $K$ dimensional low rank matrix $\mathbf{\hat{R}} \in \mathbb{R}^{N \times M}$
where $\mathbf{\hat{R}} = \mathbf{U} \mathbf{V}^\mathrm{T}$ with
$\mathbf{U} \in \mathbb{R}^{N \times K}$ and $\mathbf{V} \in \mathbb{R}^{M \times K}$
are two matrices of rank $K$ encoding a dense representation of the users and items with

\begin{equation}
\begin{aligned}
	\argmin_{\mathbf{U},\mathbf{V}}
	\sum_{(i,j) \in \mathcal{K}(\mathbf{R})}
	&( r_{ij} - \vec{\mathbf{u}}_i^{\mathrm{T}} \vec{\mathbf{v}}_j ) ^ 2 + \\
	&\lambda ( \left\| \vec{\mathbf{u}}_i \right\|_{Fro}^2 +
	\left\| \vec{\mathbf{v}}_j \right\|_{Fro}^2 )
\end{aligned}
\end{equation}

where $\mathcal{K}(\mathbf{R})$ is the set of indices of known ratings,
$\vec{\mathbf{u}}_i$ and $\vec{\mathbf{v}}_j$
are the corresponding line vectors of $\mathbf{U}$ and $\mathbf{V}$,
$\lambda$ is the coefficient that controls the influence of L2 regularization,
and $\left\| \cdot \right\|_{Fro}$ is the Frobenius norm.

Table \ref{tab:notations} summarizes the symbols used in our approach.
In the next section, we will propose a long-short interest model
to extract sequential features of users and items based on the long-short interest auumption.

\begin{table}[htpb]
    \centering
    \caption{Summary of notations.}
    \label{tab:notations}
    \begin{tabular}{|c|l|}
        \hline
        \textbf{Notation} & \textbf{Description} \\
        \hline
        $N$ & Number of users \\
        $M$ & Number of items \\
        $K$ & Dimension of latent factors \\
        $D$ & Dimension of sequential features \\
        $\mathbf{R} \in \mathbb{R}^{N \times M}$ & Rating matrix \\
        $\mathbf{U} \in \mathbb{R}^{N \times K}$ & Latent factors of users \\
        $\mathbf{V} \in \mathbb{R}^{M \times K}$ & Latent factors of items \\
        $\mathbf{X} \in \mathbb{R}^{N \times D}$ & sequential features of users \\
        $\mathbf{Y} \in \mathbb{R}^{M \times D}$ & sequential features of items \\
        \hline
    \end{tabular}
\end{table}

\subsection{Long-short Interest Model}
Collaborative filtering aims at estimating the ratings a user is going to give to
all other items he never interact with by using the ratings of all the other users.
The basic assumption of collaborative filtering is that items liked by the same user
would be similar or users like same items would share similar interest.
However, in real-world situations, it is not always true because users' interest
may change over a long time period.
Meanwhile, the interest distribution of a user in a fixed time period
are stable and don't change too much.

To describe this phenomenon that interest changes over a long time period but
keep stable in a short time period,
we propose the definition of \textbf{long interest} and \textbf{short interest}.

\begin{itemize}
\item \textbf{long interest} reflects the interest distribution of a user
in a long time period, and it is reflected in the whole items list of the user's preference.
\item \textbf{short interest} reflects the interest distribution of a user
in a short time period, and it is reflected in a fraction of the whole items list of
the user's preference in a fixed length sliding window.
\end{itemize}

Under this definition, each user will have a long interest, and each long interest will
correspond several short interest. At the same time,
we propose two assumption based on long interest and short interest.

\begin{enumerate}
\item items liked in the same short interest of the same long interest have a higher
possibility to be similar than ones liked in different short interest of the same long interest.
\item the more times items show in the same short interest of different long interest,
the higher possibility they are similar.
\end{enumerate}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.5]{images/embedding.pdf}
	\caption{A Example for Short Interest and Long Interest}
	\label{fig:embedding}
\end{figure}

For example, as illustrated in the top of Figure \ref{fig:embedding},
given a certain $\mathbf{user}$, we can see five items
$\mathbf{item1}$, $\mathbf{item2}$, ..., $\mathbf{item5}$, he liked in the last,
are list on the timeline according to the liked time order.
Those items compose the long interest of this $\mathbf{user}$.
Let's assume that the time window size of short interest is set to $2$,
That means $\mathbf{item1}$ and $\mathbf{item2}$ are in the same short interest,
$\mathbf{item2}$ and $\mathbf{item3}$ are in the same short interest, and so on.
Meanwhile $\mathbf{item2}$ and $\mathbf{item5}$ are in different short interest.
Therefore $\mathbf{item2}$ has a higher possibility to be similar with $\mathbf{item1}$
than $\mathbf{item5}$ based on our long-short interest assumption.

In special, we embed users and items into a low dimensional space
to characterize these similarity in mathematical sense.
We use European space distance between items in this low dimensional space
to represent the similarity between them.
Hence, $\mathbf{item2}$ has a higher possibility to be similar with $\mathbf{item1}$
than $\mathbf{item5}$ means $\mathbf{item2}$ is close to $\mathbf{item1}$ and far away from $\mathbf{item5}$
in this low dimensional space, as shown in the bottom of Figure \ref{fig:embedding}.

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.55]{images/doc2vec.pdf}
	\caption{Embedding Model for Extracting Interest Similarity from Users and Items}
	\label{fig:doc2vec}
\end{figure}

Inspired by paragraph2vec algorithm \cite{le2014distributed} for learning
vector representations of words which take advantage of a word order observed in a sentence,
we introduce a neural network based language model to carry out the embedding of sequential features.
The embedding model simultaneously learns vector representations of users and items
by considering the user as a global context,
and the architecture of the embedding model is illustrated in Figure \ref{fig:doc2vec}.

The training data set was derived from users interaction timeline $T$,
which comprises users $x_i (i=1,2,...,N)$ and their interacted items ordered by the interacted time,
$y_{i_1}$, $y_{i_2}$, ..., $y_{i_{L_i}}$
\footnote{we use symbol $x$ and $y$ instead of classic $u$ and $v$ to avoid confusion between $v$
and vector symbol $\mathbf{v}$ in nerual network language model.},
where $L_i$ denotes number of items interacted by user $x_i$,
which is much less than the amount of items $M$.
To characterize the \emph{long interest}, we consider the whole items list as the context and generate
the long interest of the current user.
To characterize the \emph{short interest}, we consider items in the same local interest as the context
and generate items in it one by one with the help of long interest.
More formally, objective of the embedding model is to
maximize the log-likelihood over the set of $T$ of all the interaction timeline,

\begin{equation}
\begin{aligned}
	\sum_{i=1}^{N} \bigg( &p(x_i | y_{i_1}, y_{i_2}, ..., y_{i_{L_i}}) + \\
	                      &\sum_{j=1}^{L_i} p(y_{i_j} | y_{i_{j-c}} : y_{i_{j+c}}, x_i) \bigg)
\end{aligned}
\end{equation}

where $c$ is the time window size, $y_{i_{j-c}} : y_{i_{j+c}}$ denotes the sequence
$y_{i_{j-c}}, y_{i_{j-c+1}}, ..., y_{i_{j+c}}$ excluding $y_{i_j}$.

$p(x_i | y_{i_1}, y_{i_2}, ..., y_{i_{L_i}})$ is the probability to generate
the long interest of $u_i$ based on all items he interacted.
The prediction task is typically done via a multiclass classifier,
such as softmax. There, we have

\begin{equation}
	p(x_i | y_{i_1}, y_{i_2}, ..., y_{i_{L_i}}) =
	\frac
	{
		exp ( \overline{\mathbf{v}}_{1}^{\mathrm{T}} \mathbf{v}_{x_i}^{'} )
	}
	{
		\sum_{x^{'}} exp ( \overline{\mathbf{v}}_{1}^{\mathrm{T}} \mathbf{v}_{x^{'}}^{'} )
	}
\end{equation}

where $\mathbf{v}_{x_i}^{'}$ is the output vector representation of $x_i$,
and $\overline{\mathbf{v}}_{1}$ is averaged input vector representation of all the items
interacted by user $x_i$, i.e.

\begin{equation}
	\overline{\mathbf{v}}_{1} = \frac{\sum_{j=1}^{T_i} \mathbf{v}_{y_{i_j}}}{T_i}
\end{equation}

$p(y_{i_j} | y_{i_{j-c}} : y_{i_{j+c}}, x_i)$
is the probability to generate $y_{i_j}$ based on items in the same short interest
and the user's long interest. Similarly, using softmax multiclass classifier we have

\begin{equation}
	p(y_{i_j} | y_{i_{j-c}} : y_{i_{j+c}}, x_i) =
	\frac
	{
		exp( \overline{\mathbf{v}}_{2}^{\mathrm{T}} \mathbf{v}_{y_{i_j}}^{'} )
	}
	{
		\sum_{y^{'}} exp( \overline{\mathbf{v}}_{2}^{\mathrm{T}} \mathbf{v}_{y^{'}}^{'} )
	}
\end{equation}

where $\mathbf{v}_{y_{i_j}}^{'}$ is the output vector representation of $y_{i_j}$,
and $\overline{\mathbf{v}}_{2}$ is averaged input vector representation of items
int the same short interest and corresponding long interest $x_i$.

\begin{equation}
	\overline{\mathbf{v}}_{2} = \frac{
    \mathbf{v}_{x_i} + 
    \sum_{-c \leq k \leq c, k \not= 0}{\mathbf{v}_{y_{i_{j+k}}}}
    }{2c+1}
\end{equation}

Stochastic Gradient Descent (SGD) are used as the training method,
hierarchical softmax and negative sampling are two main approaches to accelerate
the computation, and we use negative sampling approach in this paper.

\subsection{Feature based Collaborative Filtering}
Feature based collaborative filtering \cite{chen2012svdfeature} is a variety of
collaborative filtering, it allows us to build factorization models incorporating
side information such as temporal dynamics, neighborhood relationship,
and hierarchical information compare to conventional collaborative filtering,
it can also be capable of both rate prediction and collaborative ranking.

There are two kinds of side information in collaborative filtering:
user side information and item side information.
User side information could be the profiles of users, such as
gender, age and occupation.
Item side information is usually the properties of items,
it mainly depends on the recommendation sceneries.
In movie recommendation, item side information could be actor, director and genre
of the movie. In product recommendation, item side information could be the price
and category of the product.
Feature based collaborative filtering summarizes the two factors as feature vectors
(denoted by $\mathbf{u}_i \in \mathbb{R}^{n}$ and $\mathbf{v}_j \in \mathbb{R}^{m}$) and predicts
the preference score $\hat{r}$ as

\begin{equation}
\begin{aligned}
\hat{r}_{ij} = \sum_{k=1}^{n} \alpha_k \mathbf{u}_{ik} + &\sum_{k=1}^{m} \beta_k \mathbf{v}_{jk} + \\
&\left( \sum_{k=1}^{n} \mathbf{u}_{ik} \mathbf{p}_k \right) ^ \mathrm{T}
\left( \sum_{k=1}^{m} \mathbf{v}_{jk} \mathbf{q}_k \right)
\end{aligned}
\end{equation}

where $\alpha$ and $\beta$ controls the influence of each feature,
$\mathbf{p}_{k} \in \mathbb{R}^K$ and $\mathbf{q}_{k} \in \mathbb{R}^K$
are $K$ dimensional latent factors associated with each feature.
If we represent one-hot representation of users and items like

\begin{equation}
    \mathbf{u}_{ik} =
    \left\{
        \begin{aligned}
            1, &k = i \\
            0, &k \not= i
        \end{aligned}
    \right. \\
\end{equation}

\begin{equation}
    \mathbf{v}_{jk} =
    \left\{
        \begin{aligned}
            1, &k = j \\
            0, &k \not= j
        \end{aligned}
    \right. \\
\end{equation}

the equation for rating prediction will reduce to the basic matrix factorization

\begin{equation}
\hat{r}_{ij} = \alpha_i + \beta_j + \mathbf{p}_i ^ \mathrm{T} \mathbf{q}_j
\end{equation}

where $\alpha$, $\beta$ are the biases and $\mathbf{p}_i$, $\mathbf{q}_j$
are the latent factors for user $\mathbf{u}_i$ and item $\mathbf{v}_j$.

Various kinds of side information can be utilized to enhance these factors.
In some sense, the representation of users and items
learned from long-short interest model can be treated as a kind of side information,
because it distinguish the similarity and difference between users and items.

First, we define $\tilde{\mathbf{u}}_i$ as
the learned vector representation of users and $\tilde{\mathbf{v}}_j$ as
the learned vector representation of items.
Then, we get new features of users and items by add the learned vector representation
to origin one-hot representation.

\begin{equation}
    \mathbf{u}_{i} = \{ \mathbf{u}_{i} , \tilde{\mathbf{u}}_i \}
\end{equation}

\begin{equation}
    \mathbf{v}_{j} = \{ \mathbf{v}_{j} , \tilde{\mathbf{v}}_j \}
\end{equation}

There, the equation for rating prediction will change to

\begin{equation}
\begin{aligned}
\hat{r}_{ij} =
&\sum_{k=1}^{N+D} \alpha_k \{ \mathbf{u}_i , \tilde{\mathbf{u}}_i \}_k +
 \sum_{k=1}^{M+D} \beta_k  \{ \mathbf{v}_j , \tilde{\mathbf{v}}_j \}_k + \\
&\left( \sum_{k=1}^{N+D} \{ \mathbf{u}_i , \tilde{\mathbf{u}}_i \}_k \mathbf{p}_k \right) ^ \mathrm{T}
 \left( \sum_{k=1}^{M+D} \{ \mathbf{v}_j , \tilde{\mathbf{v}}_j \}_k \mathbf{q}_k \right) \\
= &\sum_{k=N+1}^{N+D} \alpha_k \tilde{\mathbf{u}}_{ik} +
 \sum_{k=M+1}^{M+D} \beta_k  \tilde{\mathbf{v}}_{jk} + \\
&\left( \sum_{k=N+1}^{N+D} \tilde{\mathbf{u}}_{ik} \mathbf{p}_k \right) ^ \mathrm{T}
 \left( \sum_{k=M+1}^{M+D} \tilde{\mathbf{v}}_{jk} \mathbf{q}_k \right) + \\
&\alpha_i + \beta_j + \mathbf{p}_i ^ \mathrm{T} \mathbf{q}_j
\end{aligned}
\end{equation}

where $N$ is the number of users, $M$ is the number of items,
$D$ is the dimension of sequential features of users and items learned from
our long-short interest model,
$\mathbf{p}_{k} \in \mathbb{R}^K$ and $\mathbf{q}_{k} \in \mathbb{R}^K$
are $K$ dimensional latent factors associated with each feature.

\section{Experiment}
In this section, we conduct several experiments to evaluate the effectiveness
of our proposed long-short interest model on
MovieLens \footnote{http://grouplens.org/datasets/movielens/}
and Netflix Prize \footnote{http://www.netflixprize.com/} dataset.
In these experiments, we also conduct corresponding analysis to investigate:
(1) the prediction performance of the long-short interest model compare to other classic methods;
(2) the influence of the long-short interest model on users own different interaction number and
(3) the effects of sequential features dimension and latent factors number.

\subsection{Experimental Setup}
\subsubsection{Dataset}
We conduct experiments on three MovieLens datasets (i.e. MovieLens-1M, MovieLens-10M and MovieLens-20M)
and Netflix Prize dataset, which are commonly used for evaluating collaborative filtering algorithms.
The MovieLens-1M dataset consists of about 1 million ratings of 6040 users and 3706 movies,
and each rating is an integer between 1 (worst) and 5 (best).
The MovieLens-10M dataset consisits of about 10 million ratings of 69878 users and 10677 movies,
the MovieLens-20M dataset consisits of about 20 million ratings of 138493 users and 26744 movies,
and each rating ranges from 0.5 (worst) to 5.0 (best) step by 0.5.
The Netflix Prize dataset consists of about 100 million ratings of 480189 users and 17770 movies,
and each rating is an integer between 1 (worst) and 5 (best).

Those datasets also provide some side information about users and items,
but we no not user them in our experiments.
Table \ref{tab:statistics} summarizes the statistics of three datasets.

\begin{table}[htpb]
    \centering
    \caption{Statistics of three MovieLens datasets and Netflix dataset.}
    \label{tab:statistics}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Dataset} & \textbf{\#Users} & \textbf{\#Items} & \textbf{\#Ratings} & \textbf{Sparsity} \\
        \hline
        ML-1M  & 6,040    & 3,706  & 1,000,209   & 95.53\% \\
        ML-10M & 69,878   & 10,677 & 10,000,054  & 98.66\% \\
        ML-20M & 138,493  & 26,744 & 20,000,263  & 99.46\% \\
        NetFlix & 480,189 & 17,770 & 100,480,507 & 98.82\% \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{Metrics}
We employ the root mean squared error (RMSE) and mean absolute error (MAE) as the evaluation metric.
RMSE and MAE are defined as:
\begin{equation}
    RSME = \sqrt{ \frac{1}{N} \sum_{i,j} I_{ij} (R_{ij} - \hat{R}_{ij})^2 }
\end{equation}
\begin{equation}
    MAE = \frac{1}{N} \sum_{i,j} I_{ij} |R_{ij} - \hat{R}_{ij}|
\end{equation}
where $N$ is the total number of ratings in the test set,
$R_{ij}$ is the ground-truth rating of user $i$ for item $j$,
$\hat{R_{ij}}$ denotes the corresponding predicted rating,
and $I_{ij}$ is abinary matrix that indicates the ratings in the test set.

\subsection{Baseline Models}
To demonstrate the superiority of our long-short interest model for rating prediction,
we compare our model model with several baseline methods.
In special, we use two popular techniques, \textbf{LibMF} and \textbf{LibFM}, that are
widely used in both academia and industry as our baseline models.

LibMF is an open source tool for approximating an incomplete matrix
using the product of two matrices in a latent space.
It provides solvers for real-valued matrix factorization,
binary matrix factorization, and one-class matrix factorization, and 
also supports parallel computation in a multi-core machine using CPU instructions
(e.g., SSE) to accelerate vector operations.
Its paper \cite{chin2015fast} won the best paper award in RecSys 2013.

Factorization machines (FM) are a generic approach that
allows to mimic most factorization models by feature engineering.
This way, factorization machines combine the generality of
feature engineering with the superiority of factorization models
in estimating interactions between categorical variables of large domain.
LibFM \cite{rendle2012factorization} is a software implementation
for factorization machines that features
Stochastic Gradient Descent (SGD) and
Alternating Least Squares (ALS) optimization as well as
Bayesian inference using Markov Chain Monte Carlo (MCMC).

\subsection{Experimental Results}
In this section, we report the experimental results to demonstrate
the effectiveness of our long-short interest model.
In the following, we denote our long-short interest model as \textbf{LSIM},
the LibMF model as \textbf{LibMF}, and LibFM with SGD optimization,
ALS optimization and MCMC optimization as \textbf{LibMF-SGD},
\textbf{LibMF-ALS} and \textbf{LibMF-MCMC} respectively.

We split the rating data in each dataset into random 90\%-10\% training-test datasets,
the training dataset are used for build the model for different algorithm and
the remaining data are used for testing. This process is repeated five times,
and we report the average RMSE and MAE.

\begin{table*}[htpb]
	\centering
	\caption{RSME Performance comparison of the proposed methods and baselines with a training ratio of 90\%/10\%
    on the MovieLens dataset and NetFlix Prize dataset.}
	\label{tab:msre}
	\begin{tabular}{|l|c|c|c|c|}
		\hline
		\textbf{Algorithms} & \textbf{MovieLens-1M} & \textbf{MovieLens-10M} & \textbf{MovieLens-20M}  & \textbf{NetFlix} \\
		\hline
		LibMF      & 0.8554 $\pm$ 0.0013 & 0.8090 $\pm$ 0.0004 & 0.8023 $\pm$ 0.0004 & 0.8630 $\pm$ 0.0002 \\
		LibFM-SGD  & 0.8641 $\pm$ 0.0015 & 0.8022 $\pm$ 0.0013 & 0.7945 $\pm$ 0.0023 & 0.8485 $\pm$ 0.0014 \\
		LibFM-ALS  & 0.8453 $\pm$ 0.0015 & 0.7936 $\pm$ 0.0004 & 0.7860 $\pm$ 0.0004 & 0.8406 $\pm$ 0.0001 \\
        LibFM-MCMC & 0.8460 $\pm$ 0.0011 & 0.7866 $\pm$ 0.0004 & 0.7787 $\pm$ 0.0005 & 0.8357 $\pm$ 0.0003 \\
		LSIM       &  &  &  & \\
		\hline
	\end{tabular}
\end{table*}

\begin{table*}[htpb]
	\centering
	\caption{MAE Performance comparison of the proposed methods and baselines with a training ratio of 90\%/10\%
    on the MovieLens dataset and NetFlix Prize dataset.}
	\label{tab:mae}
	\begin{tabular}{|l|c|c|c|c|}
		\hline
		\textbf{Algorithms} & \textbf{MovieLens-1M} & \textbf{MovieLens-10M} & \textbf{MovieLens-20M}  & \textbf{NetFlix} \\
		\hline
		LibMF      & 0.6816 $\pm$ 0.0008 & 0.6311 $\pm$ 0.0003 & 0.6229 $\pm$ 0.0004 & 0.6822 $\pm$ 0.0002 \\
		LibFM-SGD  & 0.6674 $\pm$ 0.0027 & 0.6127 $\pm$ 0.0034 & 0.6016 $\pm$ 0.0036 & 0.6517 $\pm$ 0.0046 \\
		LibFM-ALS  & 0.6609 $\pm$ 0.0010 & 0.6068 $\pm$ 0.0002 & 0.5971 $\pm$ 0.0003 & 0.6481 $\pm$ 0.0002 \\
        LibFM-MCMC & 0.6661 $\pm$ 0.0008 & 0.6039 $\pm$ 0.0002 & 0.5941 $\pm$ 0.0005 & 0.6486 $\pm$ 0.0002 \\
		LSIM       &  &  &  & \\
		\hline
	\end{tabular}
\end{table*}

Table \ref{tab:msre} and Table \ref{tab:mae} show the RSME performance and the MAE performance
of our LSIM and baseline methods on the MovieLens datasets and NetFlix Prize dataset.
The best performances are marked in bold typeface.
We can clearly observe:
(1) The prediction performance of \textbf{LibMF} is worse than other models, the reason
should be that it foucses on accelerating the training speed of matrix factorization by
parallelization, and doesn't pay more attention on the prediction precision.
(2) In three \textbf{LibFM} models, MCMC optimization \textbf{LibFM-MCMC} shows
a better performance in large datasets (MovieLens-10M, MovieLens-20M, Netflix) while
ALS optimization \textbf{LibFM-ALS} shows a better performance in small datasets (MovieLens-1M).
The performance of SGD optimization \textbf{LibFM-SGD} is the worst.
(3) Our LSIM has the best performance between those models in both RMSE and MAE performance on all datasets,
which shows the effectiveness of the long-short interest model.

To the best of our knowledge, the best results published regarding MovieLens-1M and MovieLens-10M
are reported by both (Lee et al., 2013; Sedhain et al., 2015) with a final RMSE of 0.831 ± 0.003
and 0.782 ± 0.003. These scores are obtained with a training ratio of 90\%/10\% and without side information.

% in order to exhibit the utility of side information, we report in Table 2 the RMSE conditionally to the number of miss- ing values for items. As expected, the fewer number of rat- ings for an item, the more important the side information. A more careful analysis of the RMSE improvement in this setting shows that the improvement is uniformly distributed over the users whatever their number of ratings.


% Parameter Sensitivity


\section{Conclusions}


% \section{Acknowledgments}
% The work reported in this paper is supported by the National Natural Science Foundation of China Grant 61370116.
% We thank anonymous reviewers for their beneficial comments.
% We also thank Feifan Fan and Yue Fei for valuable suggestions related to this paper.

\bibliographystyle{abbrv}
\bibliography{sigproc}

\end{document}
